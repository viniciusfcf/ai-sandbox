
#google/flan-t5-small
#mistralai/Mistral-7B-Instruct-v0.2
#model.id=mistralai/Mistral-7B-Instruct-v0.2
# quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=http://localhost:3000
# quarkus.langchain4j.huggingface.chat-model.return-full-text=false
# quarkus.langchain4j.huggingface.chat-model.log-requests=true
# quarkus.langchain4j.huggingface.chat-model.log-responses=true

quarkus.langchain4j.pgvector.dimension=4096

quarkus.langchain4j.chat-model.provider=ollama
quarkus.langchain4j.embedding-model.provider=ollama

quarkus.langchain4j.ollama.chat-model.model-id=mistral:7b-instruct-q4_K_M
quarkus.langchain4j.ollama.embedding-model.model-id=mistral:7b-instruct-q4_K_M


quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true

quarkus.langchain4j.ollama.timeout=60s